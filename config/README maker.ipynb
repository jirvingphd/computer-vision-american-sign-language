{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README MAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'images', 'eda', 'modeling', 'readme'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "config_file =\"../config/filepaths.json\"\n",
    "with open(config_file) as f:\n",
    "    FPATHS = json.load(f)\n",
    "FPATHS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# computer-vision-american-sign-language\n",
      "\n",
      "\n",
      "<center><img src=\"images/American_Sign_Language_ASL.svg\" width=500px>\n",
      "<p>By Psiĥedelisto - Own work, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=53652991\">\"https://commons.wikimedia.org/w/index.php?curid=53652991</a><p>\n",
      "</center>\n",
      "\n",
      "## Description\n",
      "\n",
      "This project aims to develop a computer vision system for American Sign Language (ASL) recognition. \n",
      "\n",
      "\n",
      "### Goals \n",
      "> - **The first/primary goal is to create a model that can classify images of letters from the ASL alphabet (26-class multi-classification)**\n",
      "- Create a streamlit application that will accept an image and predict which letter it is.\n",
      "\n",
      "> - **The second, above-and-beyond goal is to use video as the input and add object detection.**\n",
      "\n",
      "### Features\n",
      "\n",
      "- ASL letter and word translation\n",
      "- User-friendly interface\n",
      "- Support for multiple hand gestures\n",
      "\n",
      "<center><img src=\"images/Sign_language_alphabet_(58).png\" width=500px style=\"border:solid black 1px\"> \n",
      "\n",
      "<p><a href=\"https://commons.wikimedia.org/wiki/File:Sign_language_alphabet_(58).png\">Image Source</a> </p>\n",
      "<p> Raziakhatun12, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons</p>\n",
      "\n",
      "</center>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Data\n",
      "\n",
      "### Source/Download\n",
      "- Public Dataset from [Roboflow](https://public.roboflow.com/object-detection/american-sign-language-letters)\n",
      "\n",
      "\n",
      "To download:\n",
      "- Navigate to https://public.roboflow.com/object-detection/american-sign-language-letters\n",
      "- Click `->` for Downloads.\n",
      "- Select Format =  Multi-Label Classifiction\n",
      "- Download zip to computer\n",
      "\n",
      "\n",
      "### Data Details\n",
      "- 26 letters of the alphabet\n",
      "- J and Z are gesture-based letters and will likely be difficult to classify using static images.\n",
      "\n",
      "- Number of Images: 1731\n",
      "- Size: 416 x  416 \n",
      "- Channels: 3\n",
      "\n",
      "Example of Each letter:\n",
      "\n",
      "<img src=\"images/eda_example_letters.png\">\n",
      "\n",
      "\n",
      "## EDA\n",
      "\n",
      "\n",
      "\n",
      "### Class Balance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<img src=\"images/label-distribution-countplot.png\">\n",
      "\n",
      "\n",
      "\n",
      "### Methods\n",
      "\n",
      "\n",
      "- Loading Images as a Tensorflow Dataset object.\n",
      "    - Image size: 128 x 128\n",
      "    - Batch size: 32   \n",
      "    - No data augmentation due to nature of sign language.\n",
      "\n",
      "- Constructing Convolutional Neural Networks in tensorflow.\n",
      "\n",
      "\n",
      "\n",
      "#### TO DO:\n",
      "- [ ] Tune the architecture with keras tuner.\n",
      "- [ ] Attempt transfer learning\n",
      "- [ ] Save best model for deployment\n",
      "- [ ] Create a streamlit application for live inference.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intro= \"\"\"\n",
    "# computer-vision-american-sign-language\n",
    "\n",
    "\n",
    "<center><img src=\"images/American_Sign_Language_ASL.svg\" width=500px>\n",
    "<p>By Psiĥedelisto - Own work, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=53652991\">\"https://commons.wikimedia.org/w/index.php?curid=53652991</a><p>\n",
    "</center>\n",
    "\n",
    "## Description\n",
    "\n",
    "This project aims to develop a computer vision system for American Sign Language (ASL) recognition. \n",
    "\n",
    "\n",
    "### Goals \n",
    "> - **The first/primary goal is to create a model that can classify images of letters from the ASL alphabet (26-class multi-classification)**\n",
    "- Create a streamlit application that will accept an image and predict which letter it is.\n",
    "\n",
    "> - **The second, above-and-beyond goal is to use video as the input and add object detection.**\n",
    "\n",
    "### Features\n",
    "\n",
    "- ASL letter and word translation\n",
    "- User-friendly interface\n",
    "- Support for multiple hand gestures\n",
    "\n",
    "<center><img src=\"images/Sign_language_alphabet_(58).png\" width=500px style=\"border:solid black 1px\"> \n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:Sign_language_alphabet_(58).png\">Image Source</a> </p>\n",
    "<p> Raziakhatun12, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons</p>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "### Source/Download\n",
    "- Public Dataset from [Roboflow](https://public.roboflow.com/object-detection/american-sign-language-letters)\n",
    "\n",
    "\n",
    "To download:\n",
    "- Navigate to https://public.roboflow.com/object-detection/american-sign-language-letters\n",
    "- Click `->` for Downloads.\n",
    "- Select Format =  Multi-Label Classifiction\n",
    "- Download zip to computer\n",
    "\n",
    "\n",
    "### Data Details\n",
    "- 26 letters of the alphabet\n",
    "- J and Z are gesture-based letters and will likely be difficult to classify using static images.\n",
    "\n",
    "- Number of Images: 1731\n",
    "- Size: 416 x  416 \n",
    "- Channels: 3\n",
    "\n",
    "Example of Each letter:\n",
    "\n",
    "<img src=\"images/eda_example_letters.png\">\n",
    "\n",
    "\n",
    "## EDA\n",
    "\n",
    "\n",
    "\n",
    "### Class Balance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/label-distribution-countplot.png\">\n",
    "\n",
    "\n",
    "\n",
    "### Methods\n",
    "\n",
    "\n",
    "- Loading Images as a Tensorflow Dataset object.\n",
    "    - Image size: 128 x 128\n",
    "    - Batch size: 32   \n",
    "    - No data augmentation due to nature of sign language.\n",
    "\n",
    "- Constructing Convolutional Neural Networks in tensorflow.\n",
    "\n",
    "\n",
    "\n",
    "#### TO DO:\n",
    "\n",
    "- [x] Attempt transfer learning\n",
    "- [ ] Tune the architecture with keras tuner.\n",
    "- [x] Save best model for deployment\n",
    "- [ ] Create a streamlit application for live inference.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Resuls Programmaticzlly from logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD/CURRENT REULTS\n",
    "\n",
    "results= \"\"\"\n",
    "## Results\n",
    "\n",
    "\n",
    "### Best Model\n",
    "\n",
    "- EfficientNetB0\n",
    "\n",
    "\n",
    "#### Test Results\n",
    "\n",
    "\n",
    "<img src=\"images/best_model_history.png\">\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------\n",
    " Classification Metrics: Test Data\n",
    "----------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "    accuracy                           0.78       228\n",
    "   macro avg       0.78      0.79      0.77       228\n",
    "weighted avg       0.79      0.78      0.77       228\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/best_model_conf_matrix.png\">\n",
    "\n",
    "<img src=\"images/best_model_results_bar.png\">\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "CPU times: user 2min 47s, sys: 31.5 s, total: 3min 18s\n",
    "Wall time: 2min 40s\n",
    "\n",
    "- Evaluating Test Data:\n",
    "8/8 [==============================] - 2s 238ms/step - loss: 0.8256 - accuracy: 0.7763\n",
    "{'loss': 0.8255632519721985, 'accuracy': 0.7763158082962036}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
