{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Sign Language - Computer Vision Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset: https://public.roboflow.com/object-detection/american-sign-language-letters\n",
    "- Example Task: https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Set the seed for NumPy\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Set the seed for TensorFlow\n",
    "# tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom functions: add to lesson notebook instead of file\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "# sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "import ann_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of data folder\n",
    "data_dir = \"./American Sign Language Letters.v1-v1.multiclass/\"\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of img file paths (ONLY, did not make recursuve so no folders)\n",
    "img_files = glob.glob(data_dir+\"**/*\")#, recursive=True)\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an example image (at full size)\n",
    "img_loaded = load_img(img_files[0])\n",
    "img_data = img_to_array(img_loaded)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set project-wide parameters\n",
    "# # Saving image params as vars for reuse\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "TRAIN_SPLIT = 0.7  # Proportion of data for training\n",
    "VAL_SPLIT = 0.15  # Proportion of data for validation (remaining will be for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "csv_path = os.path.join(data_dir,\"train\",\"_classes.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df = df.convert_dtypes()\n",
    "# df['filename'] = df['filename']\n",
    "df = df.set_index('filename')\n",
    "df = df.astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'label'] = df.apply(lambda x: x.idxmax(), axis=1)\n",
    "display(df.head(2))\n",
    "df['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = df.drop(columns=['filename', 'label'], errors='ignore').sum()\n",
    "n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = sorted(df.drop(columns=['filename','label'], errors='ignore').columns)\n",
    "label_lookup = {i:label for i,label in enumerate(label_cols)}\n",
    "label_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the filepaths and labels\n",
    "df = df.reset_index(drop=False)\n",
    "\n",
    "df['filepath'] = df.loc[:,'filename'].astype(str).map(lambda x: os.path.join(data_dir, \"train/\", x)).values\n",
    "filepaths = df['filepath']\n",
    "\n",
    "labels = df[label_cols].astype(float).values\n",
    "filepaths[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_exist = np.array([os.path.exists(f) for f in filepaths])\n",
    "files_exist.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(load_img(filepaths[0]))\n",
    "print(f\"Letter: {label_lookup[np.argmax(labels[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create a TensorFlow dataset from the image paths and labels\n",
    "# def load_image(image_path, label, img_height=128, img_width=128):\n",
    "#     target_size=(img_height, img_width)\n",
    "#     image = load_img(image_path, target_size=target_size)\n",
    "#     image = img_to_array(image)\n",
    "#     image = image / 255.0  # Normalize the image\n",
    "#     return image, label\n",
    "\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(filename, label, img_height=128, img_width=128):\n",
    "    img = tf.io.read_file(filename)\n",
    "    # img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])  # Explicitly set the shape\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    # img = img / 255.0  # Normalize the image\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_img, ex_label = load_image(filepaths[0], labels[0])\n",
    "print(ex_img.shape)\n",
    "display(array_to_img(ex_img))\n",
    "print(f\"Label: {ex_label}\")\n",
    "print(f\"Label: {label_lookup[np.argmax(ex_label)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Example of Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Showing example of each letter\n",
    "# label_lookup.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = sorted(df['label'].unique())\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = df[['filepath', 'label']]\n",
    "eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot example of each letter\n",
    "ncols = 6\n",
    "nrows = len(labels)//ncols + 1\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(10,6))\n",
    "axes = axes.flatten()\n",
    "unique_labels = sorted(eda_df['label'].unique())\n",
    "\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    fpath = eda_df.loc[ eda_df['label']==label,'filepath'].sample(1).values[0]\n",
    "    \n",
    "    loaded = plt.imread(fpath)\n",
    "    axes[i].imshow(loaded)\n",
    "    axes[i].set_title(label)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "\n",
    "## remove unused axes\n",
    "axes_labels_diff =  len(axes) - len(unique_labels)\n",
    "\n",
    "if axes_labels_diff>0:\n",
    "    for ax in axes[-axes_labels_diff:]:\n",
    "        \n",
    "        # difference = len(axes)\n",
    "        fig.delaxes(ax=ax)   \n",
    "        \n",
    "fig.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:,'label'] = df.loc[:,label_cols].apply(lambda x: x.idxmax(), axis=1)\n",
    "# df['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = np.array(image_paths)\n",
    "# labels = np.array(labels)\n",
    "# image_paths.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Train/Test/Val Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_image(image_paths[0], labels[0])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=False)\n",
    "\n",
    "\n",
    "## Map the load_image function to the dataset\n",
    "dataset = dataset.map(load_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine split sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(TRAIN_SPLIT * total_size)\n",
    "val_size = int(VAL_SPLIT * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "print(f\"{train_size=}, {test_size=}, {val_size=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size).take(val_size)\n",
    "test_dataset = dataset.skip(train_size + val_size)\n",
    "\n",
    "# # Cache the datset for faster access\n",
    "# train_dataset = train_dataset.cache()\n",
    "# val_dataset = val_dataset.cache()\n",
    "# test_dataset = test_dataset.cache() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and prefetch the datasets\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Shuffle the trainin data\n",
    "train_dataset = train_dataset.shuffle(buffer_size=train_dataset.cardinality(), \n",
    "                                      reshuffle_each_iteration=True) # DOUBLE CHECK BATCH_SIZE * 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the datasets\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Train batch - images: {images.shape}, labels: {labels.shape}\")\n",
    "    \n",
    "for images, labels in val_dataset.take(1):\n",
    "    print(f\"Val batch - images: {images.shape}, labels: {labels.shape}\")\n",
    "    \n",
    "    \n",
    "for images, labels in test_dataset.take(1):\n",
    "    print(f\"Test batch - images: {images.shape}, labels: {labels.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moedl from https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442\n",
    "# from tensorflow\n",
    "def make_model(name='towards-data-science',show_summary=False):\n",
    "    model = models.Sequential(name=name)\n",
    "    model.add(layers.Rescaling(1./255 , input_shape = (IMG_HEIGHT,IMG_WIDTH,3)))\n",
    "    model.add(layers.Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' ))#, input_shape = (28,28,1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(layers.Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(layers.Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units = 512 , activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(units = len(label_lookup   ) , activation = 'softmax'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_callbacks(monitor='val_accuracy', patience=15, start_from_epoch=3, restore_best_weights=False):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=patience,start_from_epoch=start_from_epoch,\n",
    "                                                      monitor=monitor,\n",
    "                                                      restore_best_weights=restore_best_weights)\n",
    "    return [early_stopping]\n",
    "\n",
    "\n",
    "model = make_model(show_summary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "history = model.fit(train_dataset,epochs = 100 ,validation_data = val_dataset, callbacks=get_callbacks())\n",
    "af.evaluate_classification_network(model,X_test=test_dataset,history=history, figsize=(15,15),target_names=label_lookup.values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model2(name='CNN1',show_summary=False):\n",
    "    \n",
    "    model = models.Sequential(name=name)\n",
    "    # Using rescaling layer to scale pixel values\n",
    "    model.add(layers.Rescaling(1./255 , input_shape = (IMG_HEIGHT,IMG_WIDTH,3)))\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=16,  # How many filters you want to use\n",
    "            kernel_size=3, # size of each filter\n",
    "            # input_shape=input_shape,\n",
    "            padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))  # Size of pooling\n",
    "\n",
    "\n",
    "    # Convolutional layer\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=32,#64,  # How many filters you want to use\n",
    "            kernel_size=3,  # size of each filter\n",
    "            # input_shape=input_shape,\n",
    "            padding='same')) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))  # Size of pooling\n",
    "    \n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        layers.Dense(len(label_lookup), activation=\"softmax\") )  \n",
    "    ## Adding learning rate decay\n",
    "    lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.01, decay_steps=10000, decay_rate=0.95\n",
    "    )  # 0.9)\n",
    "    optimizer = optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = make_model2()\n",
    "history2 = model2.fit(train_dataset,epochs = 100 ,validation_data = val_dataset, callbacks=get_callbacks())\n",
    "af.evaluate_classification_network(model2,X_test=test_dataset,history=history2, figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
